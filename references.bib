@book{DirektoratJenderalKebudayaan2023,
   author = {Kementerian Pendidikan dan Kebudayaan Republik Indonesia Direktorat Jenderal Kebudayaan},
   issn = {2985-5276},
   month = {4},
   pages = {60},
   title = {Statistik Kebudayaan 2023},
   volume = {8},
   url = {https://budbas.data.kemdikbud.go.id/statistik/isi_55797b4c-197d-4108-a450-0e37cfffeb80.pdf},
   year = {2023}
}
@article{PemdaJabar,
   author = {Pemerintah Daerah Jawa Barat},
   title = {Perda no 14 Tahun 2014}
}
@misc{KerasTeam,
   author = {Keras Team},
   title = {Keras Applications},
   url = {https://keras.io/api/applications/}
}
@article{Kirana2020,
   author = {Alif Kirana and Hanny Hikmayanti},
   issn = {2715-2766},
   issue = {2},
   title = {Pengenalan Pola Aksara Sunda dengan Metode Convolutional Neural Network},
   volume = {1},
   year = {2020}
}
@techReport{Permana2023,
   abstract = {Abstrak-Aksara Sunda adalah huruf yang digunakan oleh suku Sunda untuk menulis dalam bahasa Sunda. Terdapat berbagai jenis karakter dalam aksara Sunda, termasuk karakter khusus, rarangkѐn, pasangan, aksara ngalagena, dan aksara swara. Di zaman sekarang, banyak remaja menganggap belajar aksara Sunda sulit karena bentuknya yang unik dan kompleks. Oleh karena itu, diperlukan pendekatan untuk mengatasi masalah ini. Salah satu metode yang digunakan adalah mengenali citra menggunakan Convolutional Neural Network (CNN). Dalam jurnal ini, EfficientNet dipilih sebagai arsitektur Convolutional Neural Network (CNN). EfficientNet adalah arsitektur CNN yang menyesuaikan semua dimensi kedalaman, lebar, dan resolusi pada citra secara seragam, dengan menggunakan serangkaian koefisien penskalaan yang telah ditetapkan. Dataset yang digunakan berasal dari buku elektronik berjudul "Direktori Aksara Sunda untuk Unicode" yang disusun oleh Idin Baidillah dkk, terdiri dari 5780 citra dalam format .jpg. Citra-citra tersebut akan diklasifikasikan menjadi 18 kelas, yang merupakan sampel dari aksara Sunda yang digunakan dalam penelitian ini. Parameter yang dievaluasi dalam penelitian ini mencakup akurasi, loss, recall, presisi, dan F1score. Hasil pengujian terbaik diperoleh dengan menggunakan optimizer Adam, batch size 64, learning rate 0.001, dan 100 epoch, dengan tingkat akurasi sebesar 91.8%, loss sebesar 0.344, recall sebesar 91.5%, presisi sebesar 91.8%, dan F1score sebesar 91.6%. Kata kunci-Aksara Sunda, EfficientNet, CNN.},
   author = {Gilang Sukma Permana and Sofia Sa'idah and Rita Purnamasari},
   institution = {Telkom University},
   title = {Deteksi Aksara Sunda Menggunakan Metode CNN Arsitektur EfficientNet},
   year = {2023}
}
@inproceedings{Prameswari2023,
   abstract = {The Sundanese script is a cultural heritage of the Sundanese people that deserves to be preserved. With the advances in computer vision and deep learning, the study of Indonesian local character recognition still has room for improvement and therefore needs to be encouraged. In this study, the Sundanese script used was Swara and Ngalagena script. The classification of the Sundanese script poses a significant challenge due to the complexity and variability of the script's visual patterns. Therefore, this study classifies Sundanese script using the deep learning method, namely the Transfer Learning method based on the Convolutional Neural Network. The architectures used in this research are ResNet-50, VGG-19, and MobileNet. Then to evaluate the performance of the three architectures, the evaluation metrics used in this study are Accuracy, Precision, Recall, and F1-scores will be used. The three CNN architectures show very satisfactory results in classifying Sundanese scripts. VGG-19 architecture Accuracy is 99% for training data and 95% for validation data, the ResNet-50 architecture is 97%, and for validation data is 91%. Meanwhile, the MobileNet architecture data train produces an Accuracy of 97% and data validation of 92%. Overall. The VGG-19 architecture is the best in this Sundanese script classification study.},
   author = {M.A. Prameswari and M. Dwi Sulistiyo and A.F. Ihsan},
   doi = {10.1109/ICE3IS59323.2023.10335382},
   isbn = {9798350327762},
   booktitle = {Proceedings - 2023 3rd International Conference on Electronic and Electrical Engineering and Intelligent System: Responsible Technology for Sustainable Humanity, ICE3IS 2023},
   pages = {401-406},
   title = {Classification of Handwritten Sundanese Script via Transfer Learning on CNN-Based Architectures},
   year = {2023}
}
@inproceedings{Akram2024,
   abstract = {Recognizing the handwritten Sundanese script holds significant importance in the preservation of Indonesian regional scripts. While traditional Optical Character Recognition (OCR) methods have been utilized, deep learning approaches have shown promise in enhancing handwritten character recognition. Convolutional Neural Networks (CNNs) have emerged as a prominent choice due to their efficacy in computer vision tasks. Various CNN architectures have achieved state-of-the-art results in handwritten character recognition. However, selecting activation functions remains a crucial aspect influencing CNN performance. Despite extensive research on activation functions in handwritten character recognition, there exists a gap in understanding which activation functions are optimal for training models specifically tailored to handwritten Sundanese script recognition. This study aims to address this gap by exploring the efficacy of Rectified Linear Unit (ReLU) activation functions, including Leaky ReLU, Randomized Leaky ReLU (RLReLU), and Optimized Leaky ReLU (OLReLU). In training Sundanese script OCR models, the utilization of OLReLU surpasses other activation functions. While OLReLU marginally lags behind RLReLU quantitatively on validation data, OLReLU maintains its qualitative superiority among other functions on test data, achieving the highest accuracy of 0.9875. This comparative analysis underscores the efficacy of OLReLU in the context of handwritten Sundanese script recognition, offering valuable insights for the development of robust OCR systems tailored to this regional script.},
   author = {R.R. Akram and M. Dwi Sulistiyo and A. Firman Ihsan and P. Eko Yunanto and D. Richasdy and M. Arzaki},
   doi = {10.1109/ICoDSA62899.2024.10652217},
   isbn = {9798350365351},
   booktitle = {2024 International Conference on Data Science and Its Applications, ICoDSA 2024},
   pages = {92-98},
   title = {Exploring ReLU Activation Functions in CNN for Handwritten Sundanese Script Recognition},
   year = {2024}
}
@inproceedings{Ramadan2023,
   abstract = {The Sundanese script is a cultural heritage of the Sundanese people from the land of Sunda, West Java. The Sundanese people used the Sundanese hand when they first recognized writing. Image is visual information, but not all images are of good quality. Sometimes there is noise that can damage the information in it. Therefore, this research improves image quality on Sundanese handwritten image data using the Arithmetic Mean Filter and Gaussian Filter methods to be classified using the Support Vector Machine method. The Arithmetic Mean Filter and Gaussian Filter methods effectively improve image quality. We can also see this from data classification results before and after improving image quality. Noise data on Gaussian noise, salt and pepper noise, and spackle noise before being improved gets an accuracy value of 19%, 54%, and 52%. After being improved using the Gaussian Filter method, the accuracy value increases by 52%, 56%, and 70%. Meanwhile, using the Arithmetic Mean Filter method, the accuracy value increases by 59%, 65%, and 74%. Based on the overall test results, we can conclude that the Arithmetic Mean Filter method outperforms and yields better results than the Gaussian Filter method in enhancing image quality for the classification of Sundanese script handwriting.},
   author = {D.F. Ramadan and M.D. Sulistiyo and A.F. Ihsan},
   doi = {10.1109/ICoDSA58501.2023.10276420},
   isbn = {9798350305197},
   booktitle = {2023 International Conference on Data Science and Its Applications, ICoDSA 2023},
   pages = {454-459},
   title = {Noisy Image Filtering Methods for an Improved Sundanese Script Handwriting Classification},
   year = {2023}
}
@techReport{Hayati2024,
   author = {Khairat Hayati and DrMahmud Dwi Sulistiyo and DrAditya Fiman Ihsan},
   title = {Klasifikasi Aksara Sunda Dengan Metode Machine Learning Klasik},
   year = {2024}
}
@techReport{Baidillah2008,
   author = {Idin Baidillah and Undang A Darsa and Oman Abdurahman and Tedi Permadi and Gugun Gunardi and Agus Suherman and Taufik Ampera and Harja Santana and Purba Dian and Tresna Nugraha and Dadan Sutisna},
   institution = {Pemerintah Provinsi Jawa Barat Dinas Pendidik. Provinsi Jawa Barat},
   title = {Direktori Aksara Sunda untuk Unicode},
   year = {2008}
}
@article{Hidayat2021,
   abstract = {With an increasing interest in the digitization effort of ancient manuscripts, ancient character recognition becomes one of the most important areas in the automated document image analysis. In this regard, we propose a Convolutional Neural Network (CNN)-based classifier to recognize the ancient Sundanese characters obtained from a digital collection of Southeast Asian palm leaf manuscripts. In this work, we utilize two different preprocessing techniques for the dataset. The first technique involves the use of geometric transformations, noise background addition, and brightness adjustment to augment the imbalanced samples to be fed into the classifier. The second technique makes use of the Otsu's threshold method to binarize the characters and only uses the usual geometric transformations for the data augmentation. The proposed network with different data augmentation processes is trained on the training set and tested on the testing set. Image binarization from the second technique can outperform the performance of the CNN-based classifier upon the first technique by achieving a testing accuracy of 97.74%.},
   author = {Alam Ahmad Hidayat and Kartika Purwandari and Tjeng Wawan Cenggoro and Bens Pardamean},
   doi = {10.1016/J.PROCS.2020.12.025},
   issn = {1877-0509},
   journal = {Procedia Computer Science},
   keywords = {Otsu's threshold method,ancient sundanese characters,convolutional neural network,data augmentation,document image analysis},
   month = {1},
   pages = {195-201},
   publisher = {Elsevier},
   title = {A Convolutional Neural Network-based Ancient Sundanese Character Classifier with Data Augmentation},
   volume = {179},
   year = {2021}
}
@inproceedings{Paulus2019,
   abstract = {Handwriting recognition is still a real challenge in classification tasks. Not as in modern documents, the isolated glyph images in ancient document have various random noises, non uniform background color, and smudge. Convolution neural network (CNN) is one of successful method in pattern recognition and machine learning to classify the objects. The evaluation of some CNN architectures with several different convolution layers classifying the isolated glyph image are presented in this paper. The experimental study is tested on 60 classes of glyph from the ancient Sundanese dataset that published in ICDAR 2017. Beside, the batch normalization is also investigated to measure the performance of the learning process. The results shown that the recognition rate was affected by multi convolutional layers, multi fully connected layer and batch normalization. Based on the experimental study, model 8C2F could achieve 86.15% of recognition rate.},
   author = {E. Paulus and S. Hadi and M. Suryani and I. Suryana and Y. D. Simanjuntak},
   doi = {10.1088/1742-6596/1235/1/012063},
   issn = {17426596},
   issue = {1},
   booktitle = {Journal of Physics: Conference Series},
   month = {7},
   publisher = {Institute of Physics Publishing},
   title = {Evaluating Ancient Sundanese Glyph Recognition Using Convolutional Neural Network},
   volume = {1235},
   year = {2019}
}
@misc{aksarasunda2024,
   author = {aksarasunda},
   journal = {Roboflow},
   title = {Aksara Sunda Computer Vision Project},
   url = {https://universe.roboflow.com/aksarasunda/aksara-sunda-eayhq},
   year = {2024}
}
@misc{Angelina2024,
   author = {Agatha Angelina},
   journal = {Roboflow},
   title = {Aksara Sunda Computer Vision Project},
   url = {https://universe.roboflow.com/agatha-angelina-hnexv/aksara-sunda-xvbwp},
   year = {2024}
}
@misc{TeknikInformatika2024,
   author = {Teknik Informatika},
   journal = {Roboflow},
   title = {Aksara Sunda Computer Vision Project},
   url = {https://universe.roboflow.com/teknik-informatika/aksara-sunda-4lcpy},
   year = {2024}
}
@misc{Ihsan2024,
   author = {Aditya Firman Ihsan},
   doi = {10.17632/VFJ32BPJSF.1},
   keywords = {Handwriting Recognition},
   publisher = {Mendeley Data},
   title = {Indonesian Local Script Characters},
   url = {https://data.mendeley.com/datasets/vfj32bpjsf/1},
   year = {2024}
}
@article{Tan2019,
   abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.},
   author = {Mingxing Tan and Quoc V. Le},
   isbn = {9781510886988},
   journal = {36th International Conference on Machine Learning, ICML 2019},
   month = {5},
   pages = {10691-10700},
   publisher = {International Machine Learning Society (IMLS)},
   title = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
   volume = {2019-June},
   url = {https://arxiv.org/abs/1905.11946v5},
   year = {2019}
}
@article{Tan2021,
   abstract = {This paper introduces EfficientNetV2, a new family of convolutional networks that have faster training speed and better parameter efficiency than previous models. To develop these models, we use a combination of training-aware neural architecture search and scaling, to jointly optimize training speed and parameter efficiency. The models were searched from the search space enriched with new ops such as Fused-MBConv. Our experiments show that EfficientNetV2 models train much faster than state-of-the-art models while being up to 6.8x smaller. Our training can be further sped up by progressively increasing the image size during training, but it often causes a drop in accuracy. To compensate for this accuracy drop, we propose an improved method of progressive learning, which adaptively adjusts regularization (e.g. data augmentation) along with image size. With progressive learning, our EfficientNetV2 significantly outperforms previous models on Im-ageNet and CIFAR/Cars/Flowers datasets. By pretraining on the same ImageNet21k, our Effi-cientNetV2 achieves 87.3% top-1 accuracy on ImageNet ILSVRC2012, outperforming the recent ViT by 2.0% accuracy while training 5x-11x faster using the same computing resources. Code is available at https://github.com/google/ automl/tree/master/efficientnetv2.},
   author = {Mingxing Tan and Quoc V Le},
   title = {EfficientNetV2: Smaller Models and Faster Training},
   url = {https://github.com/google/},
   year = {2021}
}
@misc{,
   author = {SHUBHAM INGOLE},
   journal = {Medium},
   title = {An Extensive Guide to Convolution Neural Network-(2023)},
   url = {https://medium.com/@singole/an-extensive-guide-to-convolution-neural-network-2023-84872b16bd78}
}
@article{Pomazan2023,
   author = {V Pomazan and I Tvoroshenko and V Gorokhovatskyi},
   title = {Handwritten character recognition models based on convolutional neural networks},
   url = {https://openarchive.nure.ua/entities/publication/09998e00-8e88-4642-b299-791755e6ea08},
   year = {2023}
}
@article{Zhao2024,
   abstract = {<p>In computer vision, a series of exemplary advances have been made in several areas involving image classification, semantic segmentation, object detection, and image super-resolution reconstruction with the rapid development of deep convolutional neural network (CNN). The CNN has superior features for autonomous learning and expression, and feature extraction from original input data can be realized by means of training CNN models that match practical applications. Due to the rapid progress in deep learning technology, the structure of CNN is becoming more and more complex and diverse. Consequently, it gradually replaces the traditional machine learning methods. This paper presents an elementary understanding of CNN components and their functions, including input layers, convolution layers, pooling layers, activation functions, batch normalization, dropout, fully connected layers, and output layers. On this basis, this paper gives a comprehensive overview of the past and current research status of the applications of CNN models in computer vision fields, e.g., image classification, object detection, and video prediction. In addition, we summarize the challenges and solutions of the deep CNN, and future research directions are also discussed.</p>},
   author = {Xia Zhao and Limin Wang and Yufei Zhang and Xuming Han and Muhammet Deveci and Milan Parmar},
   doi = {10.1007/s10462-024-10721-6},
   issn = {1573-7462},
   issue = {4},
   journal = {Artificial Intelligence Review},
   month = {3},
   pages = {99},
   title = {A review of convolutional neural networks in computer vision},
   volume = {57},
   year = {2024}
}
@article{Maharana2022,
   abstract = {This review paper provides an overview of data pre-processing in Machine learning, focusing on all types of problems while building the machine learning problems. It deals with two significant issues in the pre-processing process (i). issues with data and (ii). Steps to follow to do data analysis with its best approach. As raw data are vulnerable to noise, corruption, missing, and inconsistent data, it is necessary to perform pre-processing steps, which is done using classification, clustering, and association and many other pre-processing techniques available. Poor data can primarily affect the accuracy and lead to false prediction, so it is necessary to improve the dataset's quality. So, data pre-processing is the best way to deal with such problems. It makes the knowledge extraction from the data set much easier with cleaning, Integration, transformation, and reduction methods. The issue with Data missing and significant differences in the variety of data always exists as the information is collected through multiple sources and from a real-world application. So, the data augmentation approach generates data for machine learning models. To decrease the dependency on training data and to improve the performance of the machine learning model. This paper discusses flipping, rotating with slight degrees and others to augment the image data and shows how to perform data augmentation methods without distorting the original data.},
   author = {Kiran Maharana and Surajit Mondal and Bhushankumar Nemade},
   doi = {10.1016/J.GLTP.2022.04.020},
   issn = {2666-285X},
   issue = {1},
   journal = {Global Transitions Proceedings},
   month = {6},
   pages = {91-99},
   publisher = {Elsevier},
   title = {A review: Data pre-processing and data augmentation techniques},
   volume = {3},
   year = {2022}
}
@article{Neu2022,
   abstract = {Process mining enables the reconstruction and evaluation of business processes based on digital traces in IT systems. An increasingly important technique in this context is process prediction. Given a sequence of events of an ongoing trace, process prediction allows forecasting upcoming events or performance measurements. In recent years, multiple process prediction approaches have been proposed, applying different data processing schemes and prediction algorithms. This study focuses on deep learning algorithms since they seem to outperform their machine learning alternatives consistently. Whilst having a common learning algorithm, they use different data preprocessing techniques, implement a variety of network topologies and focus on various goals such as outcome prediction, time prediction or control-flow prediction. Additionally, the set of log-data, evaluation metrics and baselines used by the authors diverge, making the results hard to compare. This paper attempts to synthesise the advantages and disadvantages of the procedural decisions in these approaches by conducting a systematic literature review.},
   author = {Dominic A. Neu and Johannes Lahann and Peter Fettke},
   doi = {10.1007/S10462-021-09960-8/FIGURES/6},
   issn = {15737462},
   issue = {2},
   journal = {Artificial Intelligence Review},
   keywords = {Deep learning,Predictive process monitoring,Process prediction,Systematic literature review},
   month = {2},
   pages = {801-827},
   publisher = {Springer Science and Business Media B.V.},
   title = {A systematic literature review on state-of-the-art deep learning methods for process prediction},
   volume = {55},
   url = {https://link.springer.com/article/10.1007/s10462-021-09960-8},
   year = {2022}
}
@article{Batra2024,
   abstract = {In the modern era, the necessity of digitization is increasing in a rapid manner day-to-day. The healthcare industries are working towards operating in a paperless environment. Digitizing the medical lab records help the patients in hassle-free management of their medical data. It may also prove beneficial for insurance companies for designing various medical insurance policies which can be patient-centric rather than being generalized. Optical Character Recognition (OCR) technology is demonstrated its usefulness for such cases and thus, to know the best possible solution for digitizing the medical lab records, there is a need to perform an extensive comparative study on the different OCR techniques available for this purpose. It is observed that the current research is focused mainly on the pre-processing image techniques for OCR development, however, their effects on OCR performance specially for medical report digitization yet not been studied. Herein this work, three OCR Engines viz Tesseract, EasyOCR and DocTR, and six pre-processing techniques: image binarization, brightness transformations, gamma correction, sigmoid stretching, bilateral filtering and image sharpening are surveyed in detail. In addition, an extensive comparative study of the performance of the OCR Engines while applying the different combinations of the image pre-processing techniques, and their effect on the OCR accuracy is presented.},
   author = {Pulkit Batra and Nimish Phalnikar and Deepesh Kurmi and Jitendra Tembhurne and Parul Sahare and Tausif Diwan},
   doi = {10.1007/S41870-023-01610-2/TABLES/6},
   issn = {25112112},
   issue = {1},
   journal = {International Journal of Information Technology (Singapore)},
   keywords = {Classifier,Computer vision,Digitization,Feature extraction,Image pre-processing,Medical reports,Optical character recognition},
   month = {1},
   pages = {447-455},
   publisher = {Springer Science and Business Media B.V.},
   title = {OCR-MRD: performance analysis of different optical character recognition engines for medical report digitization},
   volume = {16},
   url = {https://link.springer.com/article/10.1007/s41870-023-01610-2},
   year = {2024}
}
@phdthesis{Riza2024,
   author = {Jaohar Riza and Shohag Barman and Sadia Ridita and Zaeed Mahmud and Aditi Bhattacharya},
   month = {1},
   title = {PhytoCare : A hybrid approach for identifying Rice, Potato and Corn diseases},
   year = {2024}
}
@article{Jie2020,
   author = {Yongshi Jie and Xianhua Ji and Anzhi Yue and Jingbo Chen and Yupeng Deng and Jing Chen and Yi Zhang},
   doi = {10.3390/en13246742},
   journal = {Energies},
   month = {1},
   pages = {6742},
   title = {Combined Multi-Layer Feature Fusion and Edge Detection Method for Distributed Photovoltaic Power Station Identification},
   volume = {13},
   year = {2020}
}
@article{,
   abstract = {We develop a Deep-Text Recurrent Network (DTRN) that regards scene text reading as a sequence labelling problem. We leverage recent advances of deep convo-lutional neural networks to generate an ordered high-level sequence from a whole word image, avoiding the difficult character segmentation problem. Then a deep recurrent model, building on long short-term memory (LSTM), is developed to robustly recognize the generated CNN sequences, departing from most existing approaches recognising each character independently. Our model has a number of appealing properties in comparison to existing scene text recognition methods: (i) It can recognise highly ambiguous words by leverag-ing meaningful context information, allowing it to work reliably without either pre-or post-processing; (ii) the deep CNN feature is robust to various image distortions; (iii) it retains the explicit order information in word image , which is essential to discriminate word strings; (iv) the model does not depend on pre-defined dictionary, and it can process unknown words and arbitrary strings. It achieves impressive results on several benchmarks, advancing the-state-of-the-art substantially. Text recognition in natural image has received increasing attention in computer vision and machine intelligence, due to its numerous practical applications. This problem includes two sub tasks, namely text detection (Huang, Qiao, and Tang},
   author = {Pan He and Weilin Huang and Yu Qiao and Chen Change Loy and Xiaoou Tang},
   title = {Reading Scene Text in Deep Convolutional Sequences}
}
@article{,
   abstract = {Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label un-segmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.},
   author = {Alex Graves and Alex@idsia Ch and Santiago Fernández and Faustino Gomez and Jürgen Schmidhuber and Juergen@idsia Ch},
   title = {Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks}
}
@article{Verma2022,
   author = {P Verma and GM Foomani},
   doi = {10.18178/ijmlc.2022.12.5.1095},
   issue = {5},
   journal = {International Journal of Machine Learning and Computing},
   month = {9},
   publisher = {EJournal Publishing},
   title = {Improvement in OCR Technologies in Postal Industry Using CNN-RNN Architecture: Literature Review},
   volume = {12},
   year = {2022}
}
@article{Mosbah2024,
   abstract = {In recent years, Optical character recognition (OCR) has experienced a resurgence of interest especially for contemporary Arabic data. In fact, OCR development for printed and handwritten Arabic script is still a challenging task. These challenges are due to the specific characteristics of the Arabic script. In this work, we attempt to address these challenges by creating a deep learning OCR for Arabic document recognition called ADOCRNet. It is a novel deep learning framework whose architecture is built of layers of Convolutional Neural Networks (CNNs) and Bidirectional Long Short-Term Memory (BLSTM) trained using Connectionist Temporal Classification (CTC) algorithm. In order to assess the performance of our OCR, the proposed system is performed on two printed text datasets which are P-KHATT (text line images) and APTI (word images). It's also evaluated on a handwritten Arabic text dataset IFN/ENIT (word images). According to the practical tests, the conceived model achieves strength recognition rates on the three datasets. ADOCRNet reaches a Character Error Rate (CER) of 0.01% on the P-KHATT dataset, 0.03% on the APTI dataset and a Word Error Rate (WER) of 1.09% on the IFN/ENIT dataset, which significantly outperforms the outcomes of the current systems.},
   author = {Lamia Mosbah and Ikram Moalla and Tarek M. Hamdani and Bilel Neji and Taha Beyrouthy and Adel M. Alimi},
   doi = {10.1109/ACCESS.2024.3379530},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Arabic,BLSTM,CNNs,CTC,OCR,deep learning,document recognition},
   pages = {55620-55631},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {ADOCRNet: A Deep Learning OCR for Arabic Documents Recognition},
   volume = {12},
   year = {2024}
}
@article{Dodda2024,
   abstract = {Handwriting recognition encompasses the conversion of hand-written text images into digital text, where input images yield predicted textual output. Optical Character Recognition (OCR) technology has conventionally fulfilled this role. With surging mobile phone usage, leveraging text detection via mobile cameras gains significance in fields like medical script processing and exam evaluation. To enhance image quality, noise reduction techniques like binarization and thresholding are applied. Image processing entails letter segmentation and extraction. In this paper, we propose a neural network classifier model amalgamating Convolution Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. Leveraging an existing feature dataset, the model is trained. Input images are evaluated through the neural network, yielding recognized words in a text document format. Ultimately, the predicted output is derived via Connectionist Temporal Classification (CTC)- based loss computation. Keywords: Handwritten Recognition, Deep Learning Techniques, Optical Character Recognition.},
   author = {Ratnam Dodda and S. Balakrishna Reddy and Azmera Chandu Naik and Venugopal Gaddam},
   doi = {10.32377/CVRJST2617},
   issn = {22773916},
   issue = {1},
   journal = {CVR Journal of Science \& Technology},
   month = {6},
   pages = {107-11},
   publisher = {CVR College of Engineering},
   title = {A Study on Handwritten Text Recognition Classification using Diverse Deep Learning Techniques and Computation of CTC Loss},
   volume = {26},
   year = {2024}
}
@article{Vatanchi2022,
   author = {Sajjad M Vatanchi and Hossein Etemadfard and Mahmoud Faghfour Maghrebi and Rouzbeh Shad},
   doi = {10.21203/rs.3.rs-1443377/v1},
   keywords = {ANFIS,ANN,Bidirectional LSTM,CNN,Streammow prediction,deep learning},
   title = {A Comparative Study on Forecasting of Long-term Daily Streammow using ANN, ANFIS, BiLSTM, and CNN-GRU-LSTM},
   url = {https://doi.org/10.21203/rs.3.rs-1443377/v1},
   year = {2022}
}
@article{Liu2024,
   abstract = {Deep learning, a crucial technique for achieving artificial intelligence (AI), has been successfully applied in many fields. The gradual application of the latest architectures of deep learning in the field of time series forecasting (TSF), such as Transformers, has shown excellent performance and results compared to traditional statistical methods. These applications are widely present in academia and in our daily lives, covering many areas including forecasting electricity consumption in power systems, meteorological rainfall, traffic flow, quantitative trading, risk control in finance, sales operations and price predictions for commercial companies, and pandemic prediction in the medical field. Deep learning-based TSF tasks stand out as one of the most valuable AI scenarios for research, playing an important role in explaining complex real-world phenomena. However, deep learning models still face challenges: they need to deal with the challenge of large-scale data in the information age, achieve longer forecasting ranges, reduce excessively high computational complexity, etc. Therefore, novel methods and more effective solutions are essential. In this paper, we review the latest developments in deep learning for TSF. We begin by introducing the recent development trends in the field of TSF and then propose a new taxonomy from the perspective of deep neural network models, comprehensively covering articles published over the past five years. We also organize commonly used experimental evaluation metrics and datasets. Finally, we point out current issues with the existing solutions and suggest promising future directions in the field of deep learning combined with TSF. This paper is the most comprehensive review related to TSF in recent years and will provide a detailed index for researchers in this field and those who are just starting out.},
   author = {Xinhe Liu and Wenmin Wang},
   doi = {10.3390/MATH12101504},
   issn = {2227-7390},
   issue = {10},
   journal = {Mathematics 2024, Vol. 12, Page 1504},
   keywords = {Transformer,convolutional neural network (CNN),deep learning,large language model (LLM),layer perceptron (MLP),multi,recurrent neural network (RNN),state space model (SSM),time series forecasting},
   month = {5},
   pages = {1504},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Deep Time Series Forecasting Models: A Comprehensive Survey},
   volume = {12},
   url = {https://www.mdpi.com/2227-7390/12/10/1504/htm https://www.mdpi.com/2227-7390/12/10/1504},
   year = {2024}
}
@article{Imane123,
   abstract = {Optical character recognition (OCR) for Arabic presents unique challenges due to the script's cursive nature, contextual letter forms, multiple ligatures, the presence of diacritics, and the high variability in handwritten styles. This work introduces an enhanced Arabic handwritten word recognition architecture that integrates the attention mechanism (AM) into an end-to-end framework combining convolutional neural networks (CNN), Bidirectional long short-term memory (BiLSTM), and connectionist temporal classification (CTC), while utilizing word beam search (WBS) for decoding. To address the issue of imbalanced data in the IFN/ENIT dataset, an adaptive data augmentation algorithm is proposed, focusing on underrepresented characters and words. Extensive experiments conducted across multiple train-test configurations compare the model's performance with and without attention, employing the original dataset, standard augmentation, and the proposed adaptive augmentation method. Results demonstrate that incorporating attention significantly enhances the character accuracy rate (CAR) and word accuracy rate (WAR), with further improvements observed when using adaptive augmentation. The proposed system achieves superior performance compared to previous state-of-the-art methods, particularly in handling challenging configurations, showcasing its potential for robust and scalable Arabic handwriting recognition. Article Highlights • Attention mechanism improves feature relevance for Arabic word recognition. • Adaptive data augmentation balances rare and common character frequencies. • Our model outperforms previous methods on challenging IFN/ENIT datasets. Keywords Arabic handwritten word recognition · Convolutional neural network · Biredirectional long short memory · Conxionnist temporel classification · Word beam search · Attention mechanism · IFN/ENIT dabatbase · Adaptative data augmnetation * Ammour Alae, a.ammour@ueuromed.org; Bounour Imane, imane.},
   author = {Bounour Imane and · Ammour Alae and · Khaissidi Ghizlane and Mostafa Mrabti},
   doi = {10.1007/s42452-025-06952-z},
   isbn = {0123456789},
   journal = {Discover Applied Sciences},
   pages = {460},
   title = {Enhancing Arabic handwritten word recognition: a CNN-BiLSTM-CTC architecture with attention mechanism and adaptive augmentation},
   volume = {7},
   year = {123}
}
@article{N2023,
   abstract = {The evaluation process necessitates significant work in order to effectively and impartially assess the growing number of new subjects and interests in courses. This paper aims at auto-evaluating and setting scores for individuals similar to those provided by humans using deep learning models. This system is built purely to decipher the English characters and numbers from images, convert them into text format, and match the existing written scripts or custom keywords provided by the invigilators to check the answers. The Handwritten Text Recognition (HTR) model fervors and implements an algorithm that is capable of evaluating written scripts based on handwriting and comparing it with the custom keywords provided, whereas the existing models using Convolutional Neural networks (CNN) or Recurrent Neural networks (RNN) suffer from the Vanishing Gradient problem. The core objective of this model is to reduce manual paper checking using Bidirectional Long Short Term Memory (BiLSTM) and CRNN (Convolutional Recurrent Neural Networks). It has been implemented more than the models built on conventional approaches in aspects of performance, efficiency, and better text recognition. The inputs given to the model are in the form of custom keywords; the system processes them through HTR and image processing techniques of segmentation; and the output formats the percentage obtained by the student, word error rate, number of words misspelt, synonyms produced, and the effective outcome. The system has the capability to identify and highlight errors made by students. This feature is advantageous for both students and teachers, as it saves a significant amount of time. Even if the keywords used by students do not align perfectly, the advanced processing models employed by the system possess the intelligence to provide a reasonable number of marks.},
   author = {Prabakaran N. and Kannadasan R. and Krishnamoorthy A. and Vijay Kakani},
   doi = {10.1016/J.NLP.2023.100033},
   issn = {2949-7191},
   journal = {Natural Language Processing Journal},
   month = {12},
   pages = {100033},
   publisher = {Elsevier},
   title = {A Bidirectional LSTM approach for written script auto evaluation using keywords-based pattern matching},
   volume = {5},
   url = {https://www.sciencedirect.com/science/article/pii/S2949719123000304},
   year = {2023}
}
@misc{Najam2023,
   abstract = {Arabic handwritten-text recognition applies an OCR technique and then a text-correction technique to extract the text within an image correctly. Deep learning is a current paradigm utilized in OCR techniques. However, no study investigated or critically analyzed recent deep-learning techniques used for Arabic handwritten OCR and text correction during the period of 2020–2023. This analysis fills this noticeable gap in the literature, uncovering recent developments and their limitations for researchers, practitioners, and interested readers. The results reveal that CNN-LSTM-CTC is the most suitable architecture among Transformer and GANs for OCR because it is less complex and can hold long textual dependencies. For OCR text correction, applying DL models to generated errors in datasets improved accuracy in many works. In conclusion, Arabic OCR has the potential to further apply several text-embedding models to correct the resultant text from the OCR, and there is a significant gap in studies investigating this problem. In addition, there is a need for more high-quality and domain-specific OCR Arabic handwritten datasets. Moreover, we recommend the practical development of a space for future trends in Arabic OCR applications, derived from current limitations in Arabic OCR works and from applications in other languages; this will involve a plethora of possibilities that have not been effectively researched at the time of writing.},
   author = {Rayyan Najam and Safiullah Faizullah},
   doi = {10.3390/app13137568},
   issn = {20763417},
   issue = {13},
   journal = {Applied Sciences (Switzerland)},
   keywords = {Arabic OCR,Arabic diacritization,Arabic handwritten text recognition,CTC,GANs,LSTM,Transformer,deep learning,optical character recognition,post-OCR correction},
   month = {7},
   publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
   title = {Analysis of Recent Deep Learning Techniques for Arabic Handwritten-Text OCR and Post-OCR Correction},
   volume = {13},
   year = {2023}
}
@article{Le2021,
   abstract = {Recently, deep learning (DL) models, especially those based on long short-term memory (LSTM), have demonstrated their superior ability in resolving sequential data problems. This study investigated the performance of six models that belong to the supervised learning category to evaluate the performance of DL models in terms of streamflow forecasting. They include a feed-forward neural network (FFNN), a convolutional neural network (CNN), and four LSTM-based models. Two standard models with just one hidden layer-LSTM and gated recurrent unit (GRU)-are used against two more complex models-the stacked LSTM (StackedLSTM) model and the Bidirectional LSTM (BiLSTM) model. The Red River basin-the largest river basin in the north of Vietnam-was adopted as a case study because of its geographic relevance since Hanoi city-the capital of Vietnam-is located downstream of the Red River. Besides, the input data of these models are the observed data at seven hydrological stations on the three main river branches of the Red River system. This study indicates that the four LSTM-based models exhibited considerably better performance and maintained stability than the FFNN and CNN models. However, the complexity of the StackedLSTM and BiLSTM models is not accompanied by performance improvement because the results of the comparison illustrate that their respective performance is not higher than the two standard models-LSTM and GRU. The findings of this study present that LSTM-based models can reach impressive forecasts even in the presence of upstream dams and reservoirs. For the streamflow-forecasting problem, the LSTM and GRU models with a simple architecture (one hidden layer) are sufficient to produce highly reliable forecasts while minimizing the computation time.},
   author = {Xuan Hien Le and Duc Hai Nguyen and Sungho Jung and Minho Yeon and Giha Lee},
   doi = {10.1109/ACCESS.2021.3077703},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Bidirectional LSTM,deep learning,gated recurrent unit,long short-term memory,streamflow forecasting},
   pages = {71805-71820},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Comparison of Deep Learning Techniques for River Streamflow Forecasting},
   volume = {9},
   year = {2021}
}
@article{Chit2021,
   abstract = {In this work, we explore a Connectionist Temporal Classification (CTC) based end-to-end Automatic Speech Recognition (ASR) model for the Myanmar language. A series of experiments is presented on the topology of the model in which the convolutional layers are added and dropped, different depths of bidirectional long short-term memory (BLSTM) layers are used and different label encoding methods are investigated. The experiments are carried out in low-resource scenarios using our recorded Myanmar speech corpus of nearly 26 h. The best model achieves character error rate (CER) of 4.72% and syllable error rate (SER) of 12.38% on the test set.},
   author = {Khin Me Me Chit and Laet Laet Lin},
   doi = {10.1007/978-3-030-68154-8_87},
   keywords = {Connectionist temporal classification,End-to-end automatic speech recognition,Low-resource scenarios,Myanmar speech corpus},
   title = {Exploring CTC Based End-To-End Techniques for Myanmar Speech Recognition},
   url = {https://doi.org/10.1007/978-3-030-68154-8_87},
   year = {2021}
}
@article{VaibhavKhatavkar2024,
   abstract = {Captcha are widely used to secure systems from automatic responses by distinguishing computer responses from human responses. Text, audio, video, picture picture-based Optical Character Recognition (OCR) are used for creating captcha. Text-based OCR captcha are the most often used captcha which faces issues namely, complex and distorted contents. There are attempts to build captcha detection and classification-based systems using machine learning and neural networks, which need to be tuned for accuracy. The existing systems face challenges in the recognition of distorted characters, handling variable-length captcha and finding sequential dependencies in captcha. In this work, we propose a segmentation-free OCR model for text captcha classification based on the connectionist temporal classification loss technique. The proposed model is trained and tested on a publicly available captcha dataset. The proposed model gives 99.80\% character level accuracy, while 95\% word level accuracy. The accuracy of the proposed model is compared with the state-of-the-art models and proves to be effective. The variable length complex captcha can be thus processed with the segmentation-free connectionist temporal classification loss technique with dependencies which will be massively used in securing the software systems.},
   author = {DR Vaibhav Khatavkar and DR Makarand Velankar and Sneha Petkar},
   month = {2},
   title = {Segmentation-free Connectionist Temporal Classification loss based OCR Model for Text Captcha Classification},
   url = {https://arxiv.org/pdf/2402.05417},
   year = {2024}
}
@article{Szeghalmy2023,
   abstract = {Nowadays, the solution to many practical problems relies on machine learning tools. However, compiling the appropriate training data set for real-world classification problems is challenging because collecting the right amount of data for each class is often difficult or even impossible. In such cases, we can easily face the problem of imbalanced learning. There are many methods in the literature for solving the imbalanced learning problem, so it has become a serious question how to compare the performance of the imbalanced learning methods. Inadequate validation techniques can provide misleading results (e.g., due to data shift), which leads to the development of methods designed for imbalanced data sets, such as stratified cross-validation (SCV) and distribution optimally balanced SCV (DOB-SCV). Previous studies have shown that higher classification performance scores (AUC) can be achieved on imbalanced data sets using DOB-SCV instead of SCV. We investigated the effect of the oversamplers on this difference. The study was conducted on 420 data sets, involving several sampling methods and the DTree, kNN, SVM, and MLP classifiers. We point out that DOB-SCV often provides a little higher F1 and AUC values for classification combined with sampling. However, the results also prove that the selection of the sampler–classifier pair is more important for the classification performance than the choice between the DOB-SCV and the SCV techniques.},
   author = {Szilvia Szeghalmy and Attila Fazekas},
   doi = {10.3390/S23042333},
   issn = {1424-8220},
   issue = {4},
   journal = {Sensors 2023, Vol. 23, Page 2333},
   keywords = {DOB,SCV,cross validation,imbalanced learning},
   month = {2},
   pages = {2333},
   pmid = {36850931},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {A Comparative Study of the Use of Stratified Cross-Validation and Distribution-Balanced Stratified Cross-Validation in Imbalanced Learning},
   volume = {23},
   url = {https://www.mdpi.com/1424-8220/23/4/2333/htm https://www.mdpi.com/1424-8220/23/4/2333},
   year = {2023}
}
@article{Duan2023,
   abstract = {Conodonts are jawless vertebrates deposited in marine strata from the Cambrian to the Triassic that play an important role in geoscience research. The accurate identification of conodonts requires experienced professional researchers. The process is time-consuming and laborious and can be subjective and affected by the professional level and opinions of the appraisers. The problem is exacerbated by the limited number of experts who are qualified to identify conodonts. Therefore, a rapid and simple artificial intelligence method is needed to assist with the identification of conodont species. Although the use of deep convolutional neural networks (CNN) for fossil identification has been widely studied, the data used are usually from different families, genera or even higher-level taxonomic units. However, in practical geoscience research, geologists are often more interested in classifying species belonging to the same genus. In this study, we use five fine-grained CNN models on a dataset consisting of nine species of the conodont genus Hindeodus. Based on the cross-validation results, we show that using the Bilinear-ResNet18 model and transfer learning generates the optimal classifier. Area Under Curve (AUC) value of 0.9 on the test dataset was obtained by the optimal classifier, indicating that the performance of our classifier is satisfactory. In addition, although our study is based on a very limited taxa of conodonts, our research principles and processes can be used as a reference for the automatic identification of other fossils.},
   author = {Xiong Duan},
   doi = {10.3389/FEART.2022.1046327},
   issn = {22966463},
   journal = {Frontiers in Earth Science},
   keywords = {CNN,conodont,fine-grained,hindeodus,transfer learning},
   month = {1},
   publisher = {Frontiers Media S.A.},
   title = {Automatic identification of conodont species using fine-grained convolutional neural networks},
   volume = {10},
   year = {2023}
}
@article{Shi2015,
   abstract = {Image-based sequence recognition has been a long-standing research topic in computer vision. In this paper, we investigate the problem of scene text recognition, which is among the most important and challenging tasks in image-based sequence recognition. A novel neural network architecture, which integrates feature extraction, sequence modeling and transcription into a unified framework, is proposed. Compared with previous systems for scene text recognition, the proposed architecture possesses four distinctive properties: (1) It is end-to-end trainable, in contrast to most of the existing algorithms whose components are separately trained and tuned. (2) It naturally handles sequences in arbitrary lengths, involving no character segmentation or horizontal scale normalization. (3) It is not confined to any predefined lexicon and achieves remarkable performances in both lexicon-free and lexicon-based scene text recognition tasks. (4) It generates an effective yet much smaller model, which is more practical for real-world application scenarios. The experiments on standard benchmarks, including the IIIT-5K, Street View Text and ICDAR datasets, demonstrate the superiority of the proposed algorithm over the prior arts. Moreover, the proposed algorithm performs well in the task of image-based music score recognition, which evidently verifies the generality of it.},
   author = {Baoguang Shi and Xiang Bai and Cong Yao},
   doi = {10.1109/TPAMI.2016.2646371},
   issn = {01628828},
   issue = {11},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   keywords = {Sequence recognition,convolutional neural network,long-short term memory,neural network,optical music recognition,scene text recognition},
   month = {7},
   pages = {2298-2304},
   pmid = {28055850},
   publisher = {IEEE Computer Society},
   title = {An End-to-End Trainable Neural Network for Image-based Sequence Recognition and Its Application to Scene Text Recognition},
   volume = {39},
   url = {https://arxiv.org/pdf/1507.05717},
   year = {2015}
}
@article{Wang2024,
   abstract = {Automatic speech recognition (ASR) is a typical pattern recognition technology that converts human speeches into texts. With the aid of advanced deep learning models, the performance of speech recognition is significantly improved. Especially, the emerging Audio–Visual Speech Recognition (AVSR) methods achieve satisfactory performance by combining audio-modal and visual-modal information. However, various complex environments, especially noises, limit the effectiveness of existing methods. In response to the noisy problem, in this paper, we propose a novel cross-modal audio–visual speech recognition model, named CATNet. First, we devise a cross-modal bidirectional fusion model to analyze the close relationship between audio and visual modalities. Second, we propose an audio–visual dual-modal network to preprocess audio and visual information, extract significant features and filter redundant noises. The experimental results demonstrate the effectiveness of CATNet, which achieves excellent WER, CER and converges speeds, outperforms other benchmark models and overcomes the challenge posed by noisy environments.},
   author = {Xingmei Wang and Jiachen Mi and Boquan Li and Yixu Zhao and Jiaxiang Meng},
   doi = {10.1016/J.PATREC.2024.01.002},
   issn = {0167-8655},
   journal = {Pattern Recognition Letters},
   keywords = {Attention mechanism,Audio–visual speech recognition,Cross-modal fusion,Deep learning},
   month = {2},
   pages = {216-222},
   publisher = {North-Holland},
   title = {CATNet: Cross-modal fusion for audio–visual speech recognition},
   volume = {178},
   url = {https://www.sciencedirect.com/science/article/abs/pii/S0167865524000023},
   year = {2024}
}
@article{Wu2023,
   author = {Nianheng Wu and Sebastian Padó and Roman Klinger},
   title = {Multimodal OCR post-correction on German historical documents},
   url = {https://elib.uni-stuttgart.de/bitstreams/e9a08108-4d9a-47ac-bb0b-e5704f4d6d49/download},
   year = {2023}
}
@article{Nguyen2022,
   abstract = {Optical character recognition (OCR) is one of the most popular techniques used for converting printed documents into machine-readable ones. While OCR engines can do well with modern text, their performance is unfortunately significantly reduced on historical materials. Additionally, many texts have already been processed by various out-of-date digitisation techniques. As a consequence, digitised texts are noisy and need to be post-corrected. This article clarifies the importance of enhancing quality of OCR results by studying their effects on information retrieval and natural language processing applications. We then define the post-OCR processing problem, illustrate its typical pipeline, and review the state-of-the-art post-OCR processing approaches. Evaluation metrics, accessible datasets, language resources, and useful toolkits are also reported. Furthermore, the work identifies the current trend and outlines some research directions of this field.},
   author = {Thi Tuyet Hai Nguyen and Adam Jatowt and Mickael Coustaty and Antoine Doucet},
   doi = {10.1145/3453476/SUPPL_FILE/NGUYEN.ZIP},
   issn = {15577341},
   issue = {6},
   journal = {ACM Computing Surveys},
   keywords = {OCR merging,Post-OCR processing,error model,language model,machine learning,statistical and neural machine translation},
   month = {7},
   publisher = {Association for Computing Machinery},
   title = {Survey of Post-OCR Processing Approaches},
   volume = {54},
   url = {https://dl.acm.org/doi/pdf/10.1145/3453476},
   year = {2022}
}
@article{Gerhana2020,
   abstract = {The phenomenon that occurs in the area of West Java Province is that the people do not preserve their culture, especially regional literature, namely Sundanese script, in this digital era there is research on Sundanese script combined with applications using Feature Extraction algorithm, but there is no comparison with other algorithms and cannot recognize Sundanese numbers. Therefore, to develop the research a Sundanese script application was made with the implementation of OCR (Optical Character Recognition) using the Template Matching algorithm and the Feature Extraction algorithm that was modified with the pre-processing stages including using luminosity and thresholding algorithms, from the two algorithms compared to the accuracy and time values the process of recognizing digital writing and handwriting, the results of testing digital writing algorithm Matching algorithm has a value of 87% word recognition accuracy with 236 ms processing time and 97.6% character recognition accuracy with 227 ms processing time, Feature Extraction has 98% word recognition accuracy with 73.6 ms processing time and 100% character recognition accuracy with 66 ms processing time, for handwriting recognition in feature extraction character recognition has 83% accuracy and 75% word recognition , while template matching in character recognition has an accuracy of 70% and word recognition has an accuracy of 66%.},
   author = {Yana Aditia Gerhana and Muhammad Farid Padilah and Aldy Rialdy Atmadja},
   doi = {10.15575/JOIN.V5I1.580},
   issn = {2527-9165},
   issue = {1},
   journal = {Jurnal Online Informatika},
   keywords = {Feature Extraction Algorithm,Luminosity Algorithm,Matching Template Algorithm,Script,Sundanese,Sundanese Script,Template,Thresholding,Thresholding Algorithm},
   month = {7},
   pages = {73-80},
   publisher = {Sunan Gunung Djati State Islamic University of Bandung},
   title = {Comparison of Template Matching Algorithm and Feature Extraction Algorithm in Sundanese Script Transliteration Application using Optical Character Recognition},
   volume = {5},
   url = {https://join.if.uinsgd.ac.id/index.php/join/article/view/580},
   year = {2020}
}
@article{Li2025,
   abstract = {We explore the application of Vision Transformer (ViT) for handwritten text recognition. The limited availability of labeled data in this domain poses challenges for achieving high performance solely relying on ViT. Previous transformer-based models required external data or extensive pre-training on large datasets to excel. To address this limitation, we introduce a data-efficient ViT method that uses only the encoder of the standard transformer. We find that incorporate a Convolutional Neural Network (CNN) for feature extraction instead of the original patch embedding and employ Sharpness-Aware Minimization (SAM) optimizer to ensure that the model can converge towards flatter minima yield notable enhancements. Furthermore, our introduction of the span mask technique, which masks interconnected features in the feature map, acts as an effective regularizer. Empirically, our approach competes favorably with traditional CNN-based models on small datasets like IAM and READ2016. Additionally, it establishes a new benchmark on the LAM dataset, currently the largest dataset with 19,830 training text lines. The code will be publicly available at: https://github.com/YutingLi0606/HTR-VT.},
   author = {Yuting Li and Dexiong Chen and Tinglong Tang and Xi Shen},
   doi = {10.1016/J.PATCOG.2024.110967},
   issn = {0031-3203},
   journal = {Pattern Recognition},
   keywords = {Data-efficient,Handwritten text recognition,Mask strategy,Sharpness-aware minimization,Vision transformer},
   month = {2},
   pages = {110967},
   publisher = {Pergamon},
   title = {HTR-VT: Handwritten text recognition with vision transformer},
   volume = {158},
   url = {https://www.sciencedirect.com/science/article/abs/pii/S0031320324007180},
   year = {2025}
}
@article{Ali2025,
   abstract = {Precise classification and detection of apple diseases are essential for efficient crop management and maximizing yield. This paper presents a fine-tuned EfficientNet-B0 convolutional neural network (CNN) for the automated classification of apple leaf diseases. The model builds upon a pre-trained EfficientNet-B0 base, enhanced through architectural modifications such as the integration of a global max pooling (GMP) layer, dropout, regularization, and full-model fine-tuning. To address class imbalance and improve generalization, the study adopts a holistic training strategy that integrates data augmentation, stratified data splitting, and class weighting, alongside transfer learning. The model is evaluated on the PlantVillage (PV) dataset and a curated Apple PV (APV) dataset and compared against EfficientNet-B0, EfficientNet-B3, Inception-v3, ResNet50, and VGG16 models. The fine-tuned model demonstrates outstanding test accuracies of 99.69% and 99.78% for classifying plant diseases using the APV and PV datasets, respectively. The fine-tuned model outperforms EfficientNet-B0, EfficientNet-B3, and VGG16 on both datasets and shows superior performance compared to Inception-v3 and ResNet-50 on the PV dataset. Both EfficientNet-B0 and the fine-tuned model demonstrate the lowest memory consumption and floating-point operations per second (FLOPs). Also, as compared to the EfficientNet-B0 model, the fine-tuned model achieves an 11% increase in accuracy on the APV dataset and a 49.5% accuracy improvement on the PV dataset, with approximately a 7-8% increase in both memory usage and FLOPs. The fine-tuned model thus emerges as an effective solution for plant leaf disease classification, delivering outstanding accuracy with optimized memory consumption and FLOPs, making it suitable for resource-constrained environments. This study demonstrates that fine-tuned CNN approaches, when combined with transfer learning, advanced data pre-processing, and architectural optimizations, can significantly enhance the accuracy of diseased leaf classification in crops with efficient implementation in limited-resource settings.},
   author = {Hassan Ali and Noora Shifa and Rachid Benlamri and Aitazaz A. Farooque and Raziq Yaqub},
   doi = {10.1038/S41598-025-04479-2;SUBJMETA=114,1305,1564,631;KWRD=IMAGE+PROCESSING,MACHINE+LEARNING},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   keywords = {Apple leaf diseases,CNN,Deep learning,EfficientNet-B0,Fine-tuning,Transfer learning},
   month = {12},
   pages = {1-26},
   publisher = {Nature Research},
   title = {A fine tuned EfficientNet-B0 convolutional neural network for accurate and efficient classification of apple leaf diseases},
   volume = {15},
   url = {https://www.nature.com/articles/s41598-025-04479-2},
   year = {2025}
}
@article{Philip2025,
   abstract = {Convolutional Neural Networks (CNN) have transformed the field of computer vision through their exceptional performance in image classification, face recognition, and object detection. Much of its success is due to the development of transfer learning, where pre-trained models trained on large datasets such as ImageNet are fine-tuned (adapted) for new tasks, even when only limited labeled data is available. Fine-tuning involves gradually unfreezing and retraining a pre-trained model to obtain optimal accuracy. However, determining the optimal number of layers to unfreeze remains a critical challenge. Unfreezing too few layers may limit the model's ability to adapt to task-specific features, leading to under-fitting, while fine-tuning too many layers risks over-fitting, thereby compromising generalization on unseen data.},
   author = {Adebayo Rotimi Philip},
   doi = {10.26438/ijsrcse.v13i3.703},
   issn = {2320-7639},
   issue = {3},
   journal = {International Journal of Scientific Research in Computer Science and Engineering},
   keywords = {Convolutional Neural Network,Fine-tuning,Grad-CAM,Transfer Learning,Unfreezing Graphical Abstract,pre-train},
   pages = {48-63},
   title = {Fine-Tuning Depth Analysis: Identifying the Sweet Spot for Maximum Accuracy in CNNs},
   volume = {13},
   url = {www.isroset.orghttps://doi.org/10.26438/ijsrcse.v13i3.703},
   year = {2025}
}
@article{Shetty2023,
   abstract = {AbstractIn modern deep learning, character recognition in images is a very important field of study due to its has many real life applications. The goal of this paper is to create the state-of-the-...},
   author = {Ashish Shetty and Sanjeev Sharma},
   doi = {10.1007/S11042-023-16018-0},
   issn = {15737721},
   issue = {4},
   journal = {Multimedia Tools and Applications},
   keywords = {CNN,Character recognition,Convolution Neural Network,Deep learning,Ensemble model,OCR,The Chars74K dataset},
   month = {1},
   pages = {11411-11431},
   publisher = {Springer USNew York},
   title = {Ensemble deep learning model for optical character recognition},
   volume = {83},
   url = {https://dl.acm.org/doi/10.1007/s11042-023-16018-0},
   year = {2023}
}
